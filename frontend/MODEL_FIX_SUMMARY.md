# Model Loading Fix - Quick Summary

## Problem
The app was trying to load model files from the phone's filesystem at `/.qaihm/models/...`, but those files weren't there.

## Solution Implemented
Changed the app to:
1. Look for model files in the phone's **app storage directory**: `/data/data/com.example.snap_app/files/models/llm/`
2. Detect when files are missing and show helpful setup instructions
3. Provide an **automated PowerShell script** to push files via adb

## What Changed

### 1. **GenieService.kt** - Updated model loading
- ‚úÖ Now loads from phone's app storage (not device filesystem root)
- ‚úÖ Checks for required files and validates they exist
- ‚úÖ Shows detailed error message with setup instructions when files missing
- ‚úÖ Displays file sizes and paths when loaded successfully

### 2. **ChatScreen.kt** - Fixed initialization
- ‚úÖ Now properly launches `initialize()` in a coroutine
- ‚úÖ Shows "Loading AI model..." message during init
- ‚úÖ Shows helpful setup instructions if model files not found
- ‚úÖ Disables send button until model is ready

### 3. **New Files Created**
- üìÑ **DEVICE_SETUP.md** - Complete setup guide with adb commands
- üîß **push_model_to_device.ps1** - Automated PowerShell script to push files

## How to Get Model on Your Phone

### Option 1: **Automated (Recommended)**
```powershell
# Run from frontend folder
.\push_model_to_device.ps1
```

The script will:
- Check adb connection ‚úì
- Verify model files exist on PC ‚úì
- Create directory on phone ‚úì
- Push all files automatically ‚úì
- Verify files on device ‚úì

### Option 2: **Manual Commands**
See [DEVICE_SETUP.md](DEVICE_SETUP.md) for step-by-step adb commands

## Steps to Test
1. **Prerequisites**:
   - Phone connected via USB
   - USB debugging enabled
   - Android SDK Platform Tools installed

2. **Push model files**:
   ```powershell
   .\push_model_to_device.ps1
   ```
   (Takes 5-10 minutes for ~6GB file)

3. **Open app on phone**:
   - Navigate to **AI Assistant ‚Üí Chat**
   - You should see: **"‚úÖ AI model loaded!"**

4. **Test chat**:
   - Send a message
   - You'll see a stub response (until JNI integration)

## File Details

| File | Size | Purpose |
|------|------|---------|
| model.data | ~6 GB | Compiled model weights |
| model.encodings | ~150 MB | Quantization encodings |
| tokenizer.json | ~17 MB | Token vocabulary |
| config.json | ~1 KB | Model configuration |

**Total**: ~6.2 GB (transferred to phone via USB, takes 5-10 minutes)

## If You Get an Error

### Error: "Model files not found"
```powershell
# Run this to push files:
.\push_model_to_device.ps1
```

### Error: "adb: command not found"
- Install Android SDK Platform Tools from: https://developer.android.com/tools/releases/platform-tools
- Add to PATH or specify full path

### Error: "device offline"
- Check device connection
- Enable USB debugging
- Try: `adb devices`

### Error: "No space left on device"
- Free up phone storage (need ~7GB free)
- Check: `adb  shell df`

## What Happens Next

### App Launch
1. Shows initial greeting
2. Attempts to load model from: `/data/data/com.example.snap_app/files/models/llm/`
3. If found: Shows "‚úÖ AI model loaded!"
4. If not found: Shows setup instructions with adb command

### Sending a Message
1. User types message and taps send
2. App shows typing indicator (animated dots)
3. Model processes the message
4. Response appears in chat

### Performance Notes
- **First inference**: 10-30 seconds (model warmup)
- **Subsequent**: 2-10 seconds per message
- **Memory**: Uses 3-4 GB RAM for model + inference

## Development Notes

### Current State
- ‚úÖ Model loading from phone storage
- ‚úÖ Error handling and setup guidance
- ‚úÖ APK builds and installs
- ‚è≥ Stub responses (for UI testing)

### Next Phase (JNI Integration)
- Actual LLM inference requires native JNI binding to QAIRT SDK
- See [GenieService.kt line 105+](app/src/main/java/com/example/snap_app/GenieService.kt#L105) for TODO

## File Locations After Push

```
Phone Storage:
/data/data/com.example.snap_app/files/models/llm/
‚îú‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ tokenizer.json
‚îú‚îÄ‚îÄ model.data (6 GB)
‚îú‚îÄ‚îÄ model.encodings (150 MB)
‚îî‚îÄ‚îÄ special_tokens_map.json
```

## Verify Files on Phone

```powershell
# Check if files exist and sizes
adb shell ls -lh /data/data/com.example.snap_app/files/models/llm/

# View total size
adb shell du -sh /data/data/com.example.snap_app/files/models/llm/

# Check app logs
adb logcat -s GenieService | grep -i "model"
```

## Troubleshooting Checklist

- [ ] Phone connected via USB
- [ ] USB debugging enabled (Settings ‚Üí Developer options)
- [ ] Model files exist on PC: `C:\Users\karti\.qaihm\...\`
- [ ] Ran `push_model_to_device.ps1` successfully
- [ ] Push completed without errors
- [ ] App restarted after push
- [ ] Chat shows "‚úÖ AI model loaded" message

## Next Steps After Testing

Once model loads and app works:
1. Test sending messages and receiving responses
2. Check performance/latency
3. Implement JNI for actual LLM inference
4. Test on multiple devices (if available)

---

**Status**: ‚úÖ App ready to test with model on device  
**Est. Setup Time**: 10 minutes  
**Next Test**: Push files and open app on phone
